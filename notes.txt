initial observations
- Data is balanced between the two classes (45 original images of each)
- Image dimensions are not the same
- Dataset is small

transformations
- RandomResizedCrop takes a random area of the image, between 0.6 and 1 of the original size, and then resizes it to 50x50. This prevents overtraining by training on 'new' images each epoch
- Also perform a random horizontal flip, since this does not change the integrity of the label (i.e. roads can turn left or right) and prevents overfitting
- No rotations or vertical flip because this changes the properties of the image (roads don't come down from the sky, for example)
- No grayscale because color is likely useful (fields tend to be green, roads tend to be gray)
- only resize the test data, we want to make predictions on the image not crops or flips of it

training
- training over roughly 100 epochs seems sufficient, even less might be necessary
- note that transforms are applied when images are retrieved from loader, so each epoch trains on slightly different data
- adam optimizer converged faster than sgd in my informal tests
- cross entropy loss seems like a good standard criterion for classification
- neural network is a CNN, with two convolutional layers with maxpools after, and two fully connected linear layers after
- occasionally loss becomes very large and then stays there, not sure what's happening

ask for permission to make github repo public